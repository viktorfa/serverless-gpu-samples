# Inferless config file (version: 1.0.0)
version: 1.0.0

name: hello-torch
import_source: LOCAL

# you can choose the options between ONNX, TENSORFLOW, PYTORCH
source_framework_type: PYTORCH

configuration:
  # if you want to use a custom runtime, add the runtime id below.
  # you can find it by running `inferless runtime list` or create one with `inferless runtime upload` and update this file it by running `inferless runtime select --id <RUNTIME_ID>`.
  custom_runtime_id: ''

  # if you want to use a custom volume, add the volume id and name below,
  # you can find it by running `inferless volume list` or create one with `inferless volume create -n {VOLUME_NAME}`
  custom_volume_id: ''
  custom_volume_name: ''

  gpu_type: T4
  inference_time: '120'
  is_dedicated: true
  is_serverless: false
  max_replica: '1'
  min_replica: '0'
  scale_down_delay: '5'
  vcpu: '3'
  ram: '20'
env:
  # Add your environment variables here
  # ENV: 'PROD'
secrets:
  # Add your secret ids here you can find it by running `inferless secrets list`
  # - 65723205-ce21-4392-a10b-3tf00c58988c
optional:
  # you can update file names here
  input_file_name: input.json
  output_file_name: output.json
  runtime_file_name: inferless-runtime-config.yaml
io_schema: false
model_import_id: 230039ac-e7cf-4d64-8cd2-50b16e4a3f59
